{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://www-scf.usc.edu/~ghasemig/images/sharif.png' alt=\"SUT logo\" width=200 height=200 align=left class=\"saturate\" >\n",
    "\n",
    "<br>\n",
    "<font face=\"Times New Roman\">\n",
    "<div dir=ltr align=center>\n",
    "<font color=0F5298 size=7>\n",
    "    Introduction to Machine Learning <br>\n",
    "<font color=2565AE size=5>\n",
    "    Computer Engineering Department <br>\n",
    "    Fall 2022<br>\n",
    "<font color=3C99D size=5>\n",
    "    Homework 3: Practical - Neural Network <br>\n",
    "<font color=696880 size=4>\n",
    "    Alireza Belal\n",
    "    \n",
    "    \n",
    "____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Name : Mohammad Jamshidi\n",
    "### Student Number : 98100718\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preparation\n",
    "\n",
    "In this part, you will use a dataset related to COVID-19. Load your dataset using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "covid_data = pd.read_csv('Covid Dataset.csv')\n",
    "categorical_feature_mask = covid_data.dtypes == object\n",
    "cateforical_cols = covid_data.columns[categorical_feature_mask].tolist()\n",
    "le = LabelEncoder()\n",
    "covid_data[cateforical_cols] = covid_data[cateforical_cols].apply(lambda col: le.fit_transform(col))\n",
    "covid_data = covid_data.astype(float)\n",
    "\n",
    "# Extract X and Y from the dataset\n",
    "X_total = covid_data.iloc[:, 0:20].values\n",
    "y_total = covid_data.iloc[:,20].values\n",
    "\n",
    "\n",
    "#SPLIT THE DATA INTO TRAIN AND TEST DATA \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_total, y_total, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3803, 20)\n",
      "(1631, 20)\n",
      "(3803,)\n",
      "(1631,)\n",
      "[1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DNN as nonlinear dimensionality reduction method (50 Points)\n",
    "\n",
    "Autoencoder is an unsupervised artificial neural network that compresses the data to lower dimension and then reconstructs the input back. Autoencoder finds the representation of the data in a lower dimension by focusing more on the important features getting rid of noise and redundancy. It's based on Encoder-Decoder architecture, where encoder encodes the high-dimensional data to lower-dimension and decoder takes the lower-dimensional data and tries to reconstruct the original high-dimensional data.\n",
    "\n",
    "![picture](https://drive.google.com/uc?id=1RTZwx4xL6zFV_nUENBgWlFKLKldPoyI-)\n",
    "\n",
    "In the above Diagram, X is the input data, z is the lower-dimension representation of input X and X’ is the reconstructed input data. The mapping of higher to lower dimensions can be linear or non-linear depending on the choice of the activation function.\n",
    "\n",
    "In this part you're gonna implement an autoencoder using Keras framework as dimensionally reduction module as explained [here](https://blog.keras.io/building-autoencoders-in-keras.html).\n",
    "(It would be ok to use PyTorch as well.)\n",
    "Reduce the dimension of the data to 2 dimensions and visualize the low-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "moGEgpV999cl"
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.losses import MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define layers (25 Points)\n",
    "# input_dim = X_train.shape[1]\n",
    "# encoding_dim = 2\n",
    "# input_layer = Input(shape=(input_dim, ))\n",
    "# encd1 = Dense(input_dim, activation='relu')(input_layer)\n",
    "# encd2 = Dense(15, activation='relu')(encd1)\n",
    "# encd3 = Dense(10, activation='relu')(encd2)\n",
    "# encd4 = Dense(5, activation='relu')(encd3)\n",
    "# latent = Dense(encoding_dim, activation='relu')(encd4)\n",
    "# decd1 = Dense(5, activation='relu')(latent)\n",
    "# decd2 = Dense(10, activation='relu')(decd1)\n",
    "# decd3 = Dense(15, activation='relu')(decd2)\n",
    "# decd4 = Dense(input_dim, activation='sigmoid')(decd3)\n",
    "# autoencoder = Model(inputs = input_layer, outputs = decd4)\n",
    "\n",
    "\n",
    "\n",
    "# define layers (25 Points)\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 2\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encd1 = Dense(10, activation='gelu')(input_layer)\n",
    "encd2 = Dense(5, activation='relu')(encd1)\n",
    "latent = Dense(encoding_dim, activation='relu')(encd2)\n",
    "decd1 = Dense(5, activation='relu')(latent)\n",
    "decd2 = Dense(10, activation='relu')(decd1)\n",
    "decd3 = Dense(input_dim, activation='sigmoid')(decd2)\n",
    "autoencoder = Model(inputs = input_layer, outputs = decd3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# input_dim = X_train.shape[1]\n",
    "# encoding_dim = 2\n",
    "# input_layer = Input(shape=(input_dim, ))\n",
    "# encd1 = Dense(input_dim, activation='selu')(input_layer)\n",
    "# encd2 = Dense(18, activation='selu')(encd1)\n",
    "# encd3 = Dense(16, activation='selu')(encd2)\n",
    "# encd4 = Dense(14, activation='selu')(encd3)\n",
    "# encd5 = Dense(12, activation='selu')(encd4)\n",
    "# encd6 = Dense(10, activation='selu')(encd5)\n",
    "# encd7 = Dense(8, activation='selu')(encd6)\n",
    "# encd8 = Dense(6, activation='selu')(encd7)\n",
    "# encd9 = Dense(4, activation='selu')(encd8)\n",
    "# latent = Dense(encoding_dim, activation='selu')(encd9)\n",
    "# decd1 = Dense(4, activation='selu')(latent)\n",
    "# decd2 = Dense(6, activation='selu')(decd1)\n",
    "# decd3 = Dense(8, activation='selu')(decd2)\n",
    "# decd4 = Dense(10, activation='selu')(decd3)\n",
    "# decd5 = Dense(12, activation='selu')(decd4)\n",
    "# decd6 = Dense(14, activation='selu')(decd5)\n",
    "# decd7 = Dense(16, activation='selu')(decd6)\n",
    "# decd8 = Dense(18, activation='selu')(decd7)\n",
    "# decd9 = Dense(input_dim, activation='sigmoid')(decd8)\n",
    "# autoencoder = Model(inputs = input_layer, outputs = decd9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "60/60 [==============================] - 2s 5ms/step - loss: 0.1875 - val_loss: 0.1964\n",
      "Epoch 2/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1878 - val_loss: 0.1962\n",
      "Epoch 3/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1874 - val_loss: 0.1958\n",
      "Epoch 4/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1873 - val_loss: 0.1955\n",
      "Epoch 5/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1873 - val_loss: 0.1954\n",
      "Epoch 6/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1870 - val_loss: 0.1952\n",
      "Epoch 7/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1867 - val_loss: 0.1954\n",
      "Epoch 8/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1867 - val_loss: 0.1950\n",
      "Epoch 9/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1868 - val_loss: 0.1948\n",
      "Epoch 10/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1866 - val_loss: 0.1950\n",
      "Epoch 11/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1865 - val_loss: 0.1947\n",
      "Epoch 12/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1865 - val_loss: 0.1959\n",
      "Epoch 13/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1870 - val_loss: 0.1973\n",
      "Epoch 14/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1870 - val_loss: 0.1947\n",
      "Epoch 15/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1865 - val_loss: 0.1946\n",
      "Epoch 16/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1864 - val_loss: 0.1945\n",
      "Epoch 17/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1863 - val_loss: 0.1944\n",
      "Epoch 18/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1863 - val_loss: 0.1944\n",
      "Epoch 19/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1863 - val_loss: 0.1943\n",
      "Epoch 20/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1872 - val_loss: 0.1964\n",
      "Epoch 21/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1874 - val_loss: 0.1948\n",
      "Epoch 22/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1866 - val_loss: 0.1950\n",
      "Epoch 23/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.1943\n",
      "Epoch 24/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1860 - val_loss: 0.1948\n",
      "Epoch 25/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1861 - val_loss: 0.1943\n",
      "Epoch 26/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1860 - val_loss: 0.1946\n",
      "Epoch 27/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1866 - val_loss: 0.1945\n",
      "Epoch 28/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1864 - val_loss: 0.1986\n",
      "Epoch 29/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1892 - val_loss: 0.1950\n",
      "Epoch 30/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1865 - val_loss: 0.1944\n",
      "Epoch 31/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1862 - val_loss: 0.1950\n",
      "Epoch 32/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.1945\n",
      "Epoch 33/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1859 - val_loss: 0.1948\n",
      "Epoch 34/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1859 - val_loss: 0.1941\n",
      "Epoch 35/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1858 - val_loss: 0.1942\n",
      "Epoch 36/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1863 - val_loss: 0.1951\n",
      "Epoch 37/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1862 - val_loss: 0.1944\n",
      "Epoch 38/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1859 - val_loss: 0.1947\n",
      "Epoch 39/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1860 - val_loss: 0.1941\n",
      "Epoch 40/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1860 - val_loss: 0.1940\n",
      "Epoch 41/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1859 - val_loss: 0.1941\n",
      "Epoch 42/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1859 - val_loss: 0.1941\n",
      "Epoch 43/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1859 - val_loss: 0.1942\n",
      "Epoch 44/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1859 - val_loss: 0.1947\n",
      "Epoch 45/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.1942\n",
      "Epoch 46/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1862 - val_loss: 0.1942\n",
      "Epoch 47/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1857 - val_loss: 0.1939\n",
      "Epoch 48/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.1957\n",
      "Epoch 49/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1864 - val_loss: 0.1942\n",
      "Epoch 50/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1858 - val_loss: 0.1941\n",
      "Epoch 51/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1855 - val_loss: 0.1941\n",
      "Epoch 52/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1857 - val_loss: 0.1942\n",
      "Epoch 53/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1856 - val_loss: 0.1938\n",
      "Epoch 54/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1868 - val_loss: 0.1965\n",
      "Epoch 55/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1863 - val_loss: 0.1947\n",
      "Epoch 56/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1864 - val_loss: 0.1945\n",
      "Epoch 57/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1862 - val_loss: 0.1942\n",
      "Epoch 58/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1857 - val_loss: 0.1938\n",
      "Epoch 59/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1857 - val_loss: 0.1939\n",
      "Epoch 60/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1856 - val_loss: 0.1941\n",
      "Epoch 61/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1854 - val_loss: 0.1935\n",
      "Epoch 62/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1852 - val_loss: 0.1934\n",
      "Epoch 63/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1851 - val_loss: 0.1935\n",
      "Epoch 64/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1855 - val_loss: 0.1962\n",
      "Epoch 65/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1860 - val_loss: 0.1937\n",
      "Epoch 66/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1855 - val_loss: 0.1937\n",
      "Epoch 67/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1853 - val_loss: 0.1935\n",
      "Epoch 68/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1851 - val_loss: 0.1934\n",
      "Epoch 69/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1850 - val_loss: 0.1934\n",
      "Epoch 70/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1851 - val_loss: 0.1933\n",
      "Epoch 71/200\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.1850 - val_loss: 0.1933\n",
      "Epoch 72/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1850 - val_loss: 0.1933\n",
      "Epoch 73/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1850 - val_loss: 0.1934\n",
      "Epoch 74/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1850 - val_loss: 0.1933\n",
      "Epoch 75/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1850 - val_loss: 0.1933\n",
      "Epoch 76/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1849 - val_loss: 0.1939\n",
      "Epoch 77/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1851 - val_loss: 0.1938\n",
      "Epoch 78/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1852 - val_loss: 0.1933\n",
      "Epoch 79/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1851 - val_loss: 0.1939\n",
      "Epoch 80/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1851 - val_loss: 0.1936\n",
      "Epoch 81/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1850 - val_loss: 0.1951\n",
      "Epoch 82/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1855 - val_loss: 0.1940\n",
      "Epoch 83/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1854 - val_loss: 0.1947\n",
      "Epoch 84/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1858 - val_loss: 0.1957\n",
      "Epoch 85/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1857 - val_loss: 0.1937\n",
      "Epoch 86/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1856 - val_loss: 0.1936\n",
      "Epoch 87/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1854 - val_loss: 0.1933\n",
      "Epoch 88/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1850 - val_loss: 0.1932\n",
      "Epoch 89/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1848 - val_loss: 0.1936\n",
      "Epoch 90/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1849 - val_loss: 0.1932\n",
      "Epoch 91/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1849 - val_loss: 0.1933\n",
      "Epoch 92/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1848 - val_loss: 0.1932\n",
      "Epoch 93/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1849 - val_loss: 0.1947\n",
      "Epoch 94/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1850 - val_loss: 0.1930\n",
      "Epoch 95/200\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.1847 - val_loss: 0.1932\n",
      "Epoch 96/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1848 - val_loss: 0.1934\n",
      "Epoch 97/200\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.1852 - val_loss: 0.1943\n",
      "Epoch 98/200\n",
      " 1/60 [..............................] - ETA: 0s - loss: 0.1681"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Academia\\BS\\7\\Machine Learning\\hw\\ML-practical-homeworks-fall-2022\\hw4\\Autoencoder\\Autoencoder.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Academia/BS/7/Machine%20Learning/hw/ML-practical-homeworks-fall-2022/hw4/Autoencoder/Autoencoder.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Academia/BS/7/Machine%20Learning/hw/ML-practical-homeworks-fall-2022/hw4/Autoencoder/Autoencoder.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m autoencoder\u001b[39m.\u001b[39mcompile(optimizer \u001b[39m=\u001b[39m Adam(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m), loss \u001b[39m=\u001b[39m MeanSquaredError())\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Academia/BS/7/Machine%20Learning/hw/ML-practical-homeworks-fall-2022/hw4/Autoencoder/Autoencoder.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m hist \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39;49mfit(X_train, X_train, epochs \u001b[39m=\u001b[39;49m epochs, batch_size \u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m, shuffle \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Academia/BS/7/Machine%20Learning/hw/ML-practical-homeworks-fall-2022/hw4/Autoencoder/Autoencoder.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m  validation_data \u001b[39m=\u001b[39;49m (X_test, X_test), initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Academia/BS/7/Machine%20Learning/hw/ML-practical-homeworks-fall-2022/hw4/Autoencoder/Autoencoder.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m loss_per_epoch \u001b[39m=\u001b[39m hist\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Academia/BS/7/Machine%20Learning/hw/ML-practical-homeworks-fall-2022/hw4/Autoencoder/Autoencoder.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(loss_per_epoch)\n",
      "File \u001b[1;32mc:\\Users\\mohammad\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mohammad\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\mohammad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mohammad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\mohammad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\mohammad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\mohammad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\mohammad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\mohammad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model and reduce the dimension of the data (15 Points)\n",
    "epochs = 200\n",
    "autoencoder.compile(optimizer = Adam(learning_rate=1e-3), loss = MeanSquaredError())\n",
    "hist = autoencoder.fit(X_train, X_train, epochs = epochs, batch_size = 64, shuffle = False,\n",
    " validation_data = (X_test, X_test), initial_epoch=0)\n",
    "loss_per_epoch = hist.history['loss']\n",
    "print(loss_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss Value')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "epochs = np.array([i+1 for i in range(epochs)])\n",
    "ax.plot(epochs, loss_per_epoch, '-o')\n",
    "ax.set_title('Validation Loss Value per Number of Epochs')\n",
    "ax.set_xlabel('Number of Epoch')\n",
    "ax.set_ylabel('Loss Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 1ms/step\n",
      "51/51 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(inputs = input_layer, outputs= latent)\n",
    "encoded_input = Input(shape = (encoding_dim, ))\n",
    "encoded_train = pd.DataFrame(encoder.predict(X_train))\n",
    "encoded_test = pd.DataFrame(encoder.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3.2472074e-30 2.3357894e-02 1.0000000e+00 1.7470484e-27 4.2222597e-19\n",
      "  8.8114394e-10 1.0000000e+00 2.4947622e-05 9.9999976e-01 2.9946646e-05\n",
      "  1.4856901e-27 1.3640408e-15 1.0000000e+00 1.5194813e-23 0.0000000e+00\n",
      "  0.0000000e+00 1.3842362e-17 1.7028894e-21 0.0000000e+00 0.0000000e+00]\n",
      " [8.9761478e-01 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 9.9999678e-01\n",
      "  1.0000000e+00 1.5300079e-17 9.9999988e-01 1.0394133e-11 9.9925280e-01\n",
      "  2.5011759e-04 1.0000000e+00 1.1142994e-04 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 2.5073398e-14\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.0823331e-07\n",
      "  4.0902153e-27 1.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      "  1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 9.9999911e-01\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4062861e-06\n",
      "  1.1366688e-29 1.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      "  1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 2.0579384e-11\n",
      "  0.0000000e+00 9.4899730e-07 2.0673666e-24 0.0000000e+00 9.9990004e-01\n",
      "  1.0000000e+00 1.0000000e+00 1.7774780e-37 1.6120066e-03 3.0745456e-12\n",
      "  1.0000000e+00 5.5813618e-15 1.0000000e+00 0.0000000e+00 0.0000000e+00]], shape=(5, 20), dtype=float32)\n",
      "[[1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0.]\n",
      " [0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0.]\n",
      " [1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "predicted_X_train = autoencoder(X_train)\n",
    "# print(predicted_X_train[7])\n",
    "# print(predicted_X_train.shape)\n",
    "# print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0          1\n",
      "0      1.163220   4.762868\n",
      "1     15.118462   0.000000\n",
      "2     47.616325  16.253077\n",
      "3     48.697876  14.709255\n",
      "4     22.524694   7.652384\n",
      "...         ...        ...\n",
      "3798   0.000000   2.861007\n",
      "3799  20.537453  14.700619\n",
      "3800  27.684927  13.980925\n",
      "3801  25.407015  13.096668\n",
      "3802  12.918259   1.428163\n",
      "\n",
      "[3803 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(encoded_train)\n",
    "# print(encoded_test)\n",
    "plt.scatter(encoded_train[:][0], encoded_train[:][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the encoded data (10 Points)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "91b410dd9a8bb11c536d001ad40742c19c082a60dfe79daca26509b38e876541"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
